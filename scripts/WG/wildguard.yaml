model:
  name_or_path: s3://ai2-llm/pretraining-data/sources/reddit/dolma_raw/wildguard_tagging/wildguard
  num_scheduler_steps: 1

format:
  chat_template: |
    {%- for message in messages -%}
      {%- if message['role'] == 'user' -%}
        {{- '<s> <|user|>\n' -}}
        {{- "[INST] You are a classifier for analyzing interactions between humans and LLMs. Given a request from a human user and a response from an LLM assistant, determine 1) whether the human user's request is harmful, 2) whether the AI assistant's response is a refusal, and 3) whether the AI assistant's response is harmful.\n\n" -}}
        {{- 'Human user:\n' + message['content'] | trim + '\n\n' -}}
        {{- 'AI assistant:\n\n\n---\n\n' -}}
        {{- 'Answers: [/INST]\n<|assistant|>\n' -}}
      {%- elif message['role'] == 'assistant' -%}
        {{- '' -}}
      {%- endif -%}
    {%- endfor -%}


generate:
  max_tokens: 128
  temperature: 0.0
  top_p: 1.0

pipeline:
  sqs_queue_name: redd-class
  num_workers: 2
  generation_batch_size: 512
  output_serializer: default
  target_bucket: ai2-llm
  target_object_prefix: pretraining-data/sources/reddit/dolma_raw/wildguard_tagging/tagged_full_new2

task:
  budget: ai2/oe-data
  name: wildguard-tagging-test
  replicas: 4
  priority: HIGH
  gpu_count: 8
  workspace: ai2/reddit
  cluster:
    - ai2/jupiter-cirrascale-2
    - ai2/pluto-cirrascale